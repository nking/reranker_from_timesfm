rough sketch for feasibility before design docs:

goal is to create a real-time re-ranker for the movielens 
recommendations that uses the time information to re-rerank results.

TimesFM2.5 can provide sequential context calibration through the 
seasonality in the dynamic covariate data.

The TimesFM2.5 pretrained model can predict ratings quantiles
with dynamic covariates that hold movie embeddings and time
information, and future covariates that hold candidate movie
embeddings and time information.

With a horizon of 1 and time=now for each candidate movie,
the results are scored using percents of the quantiles.

The overall point-wise comparison can be efficient even for 200
or so candidates due to JAX/Flax backend and running on a GPU.

tfm_model = timesfm.TimesFm(
    context_len=1024,
    horizon_len=1,
    conf_interval=[0.1, 0.5, 0.9],
    backend="gpu",
    use_continuous_quantile_head=True 
)

tiling with JAX ... to broadcast

example: 
n = 100 ratings for a user
horizon = 1
- target_ratings is an array of users ratings of length n.
- movie_embeddings is an array of length n.
  each embedding is:
   [movie_embedding, hour_sin, hour_cos, day_sin, day_cos,
   month_sin, month_cos, is_holiday]
   where hour_sin, for example, is sin(2*pi*hour/24)
   where month_sin, for example, is sin(2*pi*month/12)
- candidate_movies is an array of length horizon;
  each embedding is:
   [movie_embedding, hour_now_sin, hour_now_cos,
   day_now_sin, day_now_cos, month_now_sin, month_now_cos, is_holiday]

this gets modified for batched inputs from jnp.tile:
  fm_model.forecast_with_covariates(
    inputs=[target_ratings],
    dynamic_covariates=[movie_embeddings],
    future_covariates=[candidate_movies], horizon=horizon)

P10: is safe rank.  
  model is confident that user won't hate it.
  has the lowest probability of a negative event.
P50: is moderate rank
  the median, expected rating
P90: is risky, exploration rank.  
  has highest probability of a negative outcome
  polarizing, user might love or hate it.

for each movie:
final_score = (0.7 * P50) + (0.3 * P90)

#here are some notes on distributed batch inference w/JAX:
import jax.numpy as jnp
batched_history = jnp.tile(target_ratings, (num_candidates, 1)) 
batched_dynamic_cov = jnp.tile(movie_embeddings, (num_candidates, 1, 1))batched_candidates = candidate_pool[:, jnp.newaxis, :]
forecast_output = model.forecast_with_covariates(
    inputs=batched_history,
    dynamic_covariates=batched_dynamic_cov,
    future_covariates=batched_candidates,
    horizon=1
)
predicted_ratings = forecast_output.point_forecast



-- follow up on FITS (Fourier Interpolation Time Series) for IoT




